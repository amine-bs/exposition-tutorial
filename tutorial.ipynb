{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dévéloppement d'une API ou d'une application web en Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FastAPI\n",
    "\n",
    "FastAPI est un framework qui sert à développer des API REST en Python. Il autorise la programmation asynchrone.\n",
    "\n",
    "On commence notre code par importer la classe ``fastapi.FastAPI`` et définir notre application comme une instance de cette classe.\n",
    "\n",
    "Deux notions importantes qui permettent à FastAPI de traiter les requêtes sont: le chemin et l'opération. \n",
    "- Le chemin fait référence à la dernière partie de l'URL à partir du premier \"/\". Par exemple, dans l'URL \"https://www.sspcloud.fr/formation\", le chemin est ```/formation```.\n",
    "\n",
    "- l'opération est une méthode HTTP: POST (création de données), GET (lecture), PUT (modifier), DELETE (supprimer)...\n",
    "\n",
    "Dans le protocole HTTP, on communique avec chaque chemin en utilisant une ou plusieurs de ces opérations. Ainsi, dans notre API, on va définir un path et une opération pour chaque fonction qu'on va proposer.\n",
    "\n",
    "Pour ce faire, on précède chaque fonction par l'expression suivante: ```@app_name.operation(path)```.\n",
    "\n",
    "- Dans le code suivant, la fonction **root** sert comme un accueil pour l'API et elle retourne un message d'accueil. Elle est précédée par ```@app.get('/')```. Cette expression indique à FastAPI que la fonction \"root\" est chargée des requêtes qui vont au chemin \"/\", en utilisant l'opération \"get\".\n",
    "\n",
    "- La fonction **predict** prend en entrée un fichier image et donne en retour la classe de l'image ainsi que la probabilité de la prédiction. On utilise la syntaxe ``async`` et ``await`` pour qu'elle soit asynchrone. Cela indique à Python d'éxecuter d'autres tâches en attendant que les données soient envoyées du client au serveur à travers le réseau. Cette méthode permet au serveur d'optimiser son temps de réponse.\n",
    "\n",
    "- On définit également une fonction **details** sur le chemin ``/model/{info}`` et en utilisant l'opération ``get`` pour afficher des informations sur le modèle. Le paramètre ``info`` est appelé paramètre de chemin et il est à préciser par le client dans sa requête. Par exemple, le chemin ``/model/accuracy`` retourne la précision du modèle. \n",
    "On ajoute aussi un paramètre de requête de type entier appelé ``n``. Ce paramètre est un entier qui permet de préciser le nombre de chiffres après la virgule dans la précision. On définit ce paramètre dans la requête comme dans l'exemple suivant: ``model/accuracy?n=1``.\n",
    "\n",
    "FastAPI génère une documentation et une interface utilisateur pour l'API automatiquement en utilisant ``OpenAPI``. Cette interface est disponible dans le chemin ``/docs``. Vous pouvez consulter une instance de l'API créée dans ce tutoriel [en cliquant ici](https://fastapi-tuto.lab.sspcloud.fr/docs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#install dependencies\n",
    "!pip install fastapi\n",
    "!pip install uvicorn\n",
    "!pip install python-multipart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Fichier main de l'API***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "from fastapi import FastAPI, File, UploadFile\n",
    "from utils import load_device, import_model, predict, is_image_file\n",
    "from PIL import Image\n",
    "\n",
    " \n",
    "app = FastAPI()\n",
    "\n",
    "def read_image(file):\n",
    "    img = Image.open(BytesIO(file))\n",
    "    return img\n",
    "\n",
    "device = load_device()\n",
    "model = import_model(bucket=\"mbenxsalha\", key=\"diffusion/state_dict.pickle\", device=device)\n",
    "\n",
    "#url: localhost:8000\n",
    "@app.get(\"/\")\n",
    "def root():\n",
    "    return {\"message\": \"Welcome to Image Classification FastAPI\"}\n",
    "\n",
    "#url: localhost:8000/model\n",
    "@app.get(\"/model/{info}\")\n",
    "def details(info:str, n:int=2):\n",
    "    accuracy = 99.2511111\n",
    "    if info == 'model':\n",
    "        return {'model': 'ResNet18'}\n",
    "    elif info == 'dataset':\n",
    "        return {'dataset url': \"https://www.kaggle.com/datasets/carlosrunner/pizza-not-pizza\"}\n",
    "    elif info == 'accuracy':\n",
    "        formatted_accuracy = int((10**n)*accuracy)/(10**n)\n",
    "        return {'accuracy': '{}'.format(formatted_accuracy)}\n",
    "    else:    \n",
    "        return '{} is not available'.format(info)\n",
    "\n",
    "#url: localhost:8000/predict\n",
    "@app.post(\"/predict\")\n",
    "async def predict_api(file: UploadFile = File(...)):\n",
    "    if not is_image_file(file.filename):\n",
    "        return \"file must have image format\"\n",
    "    img = read_image(await file.read())\n",
    "    preds = predict(img, model, device)\n",
    "    return preds\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pour lancer l'API, on utilise \"uvicorn\" qui permet d'exécuter un code asynchrone sur Python.**\n",
    "Dans le code suivant, ``main`` fait référence au fichier main.py qui contient le même code que la cellule précédente.\n",
    "\n",
    "La tag ``--reload`` permet de relancer l'API automatiquement si le code est modifié."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!uvicorn main_fastapi:app --reload --host=0.0.0.0 --proxy-headers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le notebook ``examples-fastapi.ipynb`` illustre comment communiquer et envoyer des requêtes à l'instance que vous venez de créer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flask\n",
    "\n",
    "La répertoire doit contenir deux dossiers: \"templates\" et \"static\".\n",
    "\n",
    "- Le dossier ``templates`` contient les templates html que flask utilisera pour construire les pages web. \n",
    "\n",
    "- Le dossier ``static`` contient des fichiers d'affichage (image, ficher css..)\n",
    "\n",
    "On commence par importer la classe Flask et définir une instance qui sera notre application.\n",
    "Le site contient deux pages: une page d'accueil et une page pour afficher les résulats.\n",
    "Ainsi, on va définir une fonction et un template html pour chaque page.\n",
    "Le code de chaque fonction est précédée par la synatxe ```@app.route(chemin:str, methods:list)```. Cette expression indique à Flask que cette fonction est chargée de requêtes qui vont au chemin indiqué et qui utilisent la liste de méthodes indiquée.\n",
    "\n",
    "Chaque fonction donne en sortie ```render_template('page.html')``` qui indique à Flask la template à interpréter pour cette fonction.\n",
    "\n",
    "La fonction **predict** retourne également des variables (pred, user_image) qui serviront à définir les valeurs des variables output et user_image dans le fichier predict.html.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#install flask\n",
    "!pip install flask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Fichier main de l'application Flask***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "from flask import Flask, render_template, request\n",
    "from utils import load_device, import_model, predict, load_image\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "def read_image(file):\n",
    "    img = Image.open(BytesIO(file))\n",
    "    return img\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "device = load_device()\n",
    "model = import_model(bucket=\"mbenxsalha\", key=\"diffusion/state_dict.pickle\", device=device)\n",
    "\n",
    "\n",
    "@app.route(\"/\", methods=[\"GET\", \"POST\"])\n",
    "def home():\n",
    "    return render_template('home.html')\n",
    "\n",
    "@app.route(\"/predict\", methods=[\"GET\", \"POST\"])\n",
    "def predict_flask():\n",
    "    if request.method == \"POST\":\n",
    "        file = request.files['file']\n",
    "        filename = file.filename\n",
    "        file_path = os.path.join('static', filename)\n",
    "        file.save(file_path)\n",
    "        img = load_image(file_path)\n",
    "        pred = predict(img, model, device)\n",
    "    return render_template(\"predict.html\", output=pred, user_image = file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On exécute la commande suivante pour lancer l'application. ``main_flask`` fait référence au fichier ``main_flask.py``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!flask --app main_flask run --host=0.0.0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous pouvez consulter l'application que vous venez de créer en changeant le lien du notebook comme dans l'exemple suivant: \n",
    "- lien de notebook: https://user-username-239011-0.user.lab.sspcloud.fr/\n",
    "- modifier le \"-0\" par \"-user\". Donc pour cet exemple, le lien de l'application est: https://user-username-239011-user.user.lab.sspcloud.fr/\n",
    "\n",
    "Créer ce lien et donc communiquer avec l'application depuis l'extérieur est possible en autorisant l'activation d'un port de service personnalisé (via ``jupyter-python configurations Networking`` avant de lancer le notebook) et en réglant le paramètre ``custom service port`` sur lequel votre application s'exécutera."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streamlit\n",
    "\n",
    "Streamlit est une bibliothèque Python qui permet de créer des application web sans avoir besoin de savoir le développement web. \n",
    "\n",
    "On écrit les différentes parties dans l'ordre que l'on souhaite s'afficher sur la page web. \n",
    "- ``st.title(title:str)`` permet d'afficher un titre\n",
    "- ``st.write(text:str)`` permet d'écrire un texte\n",
    "- ``st.file_uploader()`` permet d'ajouter un bouton ``upload`` pour importer des fichiers. Le fichier importé sera sous la forme de bytes.\n",
    "\n",
    "Streamlit permet aussi de mettre des données en cache. Cela est utile pour enregistrer les résultats de fonctions qu'on utilise souvent avec les mêmes paramètres (``import_model`` par exemple). Donc, Streamlit va calculer la fonction seulement pour la première exécution. Cela est possible avec la synatxe ``@st.cache()`` qu'on écrit avant la fonction qu'on veut enregistrer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#install streamlit\n",
    "!pip install streamlit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Fichier utils de l'application streamlit***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torch\n",
    "from model import ResNet\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms.functional as TF\n",
    "import streamlit as st\n",
    "import boto3\n",
    "import pickle\n",
    "\n",
    "IMG_EXTENSIONS = [\n",
    "    '.jpg', '.JPG', '.jpeg', '.JPEG',\n",
    "    '.png', '.PNG', '.ppm', '.PPM', '.bmp', '.BMP']\n",
    "\n",
    "#@st.cache()\n",
    "def import_model(bucket, key=\"diffusion/state_dict.pickle\", device=torch.device('cpu')):\n",
    "    s3 = boto3.client('s3',endpoint_url='https://minio.lab.sspcloud.fr/')\n",
    "    data = s3.get_object(Bucket=bucket, Key=key)\n",
    "    state_dict = pickle.loads(data['Body'].read())\n",
    "    model = ResNet()\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def load_image(file):\n",
    "    img = Image.open(file).convert(\"RGB\")\n",
    "    return img\n",
    "\n",
    "def predict(img, model, device):\n",
    "    img = TF.to_tensor(img)\n",
    "    img = TF.normalize(img, [0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    img = img.to(device)\n",
    "    img = img.unsqueeze(0)\n",
    "    preds = model(img)\n",
    "    preds = F.softmax(preds, dim=1)\n",
    "    if float(preds[0][0]) < float(preds[0][1]):\n",
    "        results = \"There is a ship!\"\n",
    "    else:\n",
    "        results = \"There is no ship!\"\n",
    "    return results\n",
    "\n",
    "@st.cache()\n",
    "def load_device():\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "    return device\n",
    "@st.cache()\n",
    "def is_image_file(filename):\n",
    "  return any(filename.endswith(extension) for extension in IMG_EXTENSIONS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Fichier main de l'application Streamlit***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = load_device()\n",
    "model = import_model(bucket=\"mbenxsalha\", key=\"diffusion/state_dict.pickle\", device=device)\n",
    "\n",
    "st.title(\"Welcome to The Ship Detective!\")\n",
    "st.write(\"The image you upload will be fed to a Deep Neural Network in real-time to verify if there is a ship or not\")\n",
    "file = st.file_uploader(\"Upload an image\")\n",
    "\n",
    "if file:\n",
    "    img = load_image(file)\n",
    "    predictions = predict(img, model, device)\n",
    "    st.title(\"Here is the image you uploaded\")\n",
    "    resized_image = img.resize((340, 340))\n",
    "    st.image(resized_image)\n",
    "    st.title(\"Prediction:\")\n",
    "    st.write(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!streamlit run main_streamlit.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "99fcf9d4a50a3fc60922dfe5bdeaa49edaa2538f7421467a5da4b84b1899b3d5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
